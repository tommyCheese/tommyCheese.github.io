[{"content":"\u003ch1 id=\"再读整洁架构之道二\"\u003e再读整洁架构之道（二）\u003c/h1\u003e\n\u003cp\u003e编程范式指的是程序的编写模式，它告诉我们应该在什么时候采用什么样的代码结构。\u003c/p\u003e\n\u003cp\u003e截止目前，一共出现了三种编程范式：结构化编程范式、面向对象编程范式和函数式编程。\u003c/p\u003e\n\u003cp\u003e作者认为，每种编程方式不是在给架构设计者的武器库进行扩充，相反，架构师和程序员的武器已经够多了，这三种编程范式是在对他们利用的武器进行\u003cstrong\u003e限制\u003c/strong\u003e，这也是为什么他们叫做“范式”。\u003c/p\u003e\n\u003ch2 id=\"结构化编程范式\"\u003e结构化编程范式\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e结构化编程对程序控制权的直接转移进行了限制和规范，特别指的是限制了程序中goto的随意使用。\u003c/strong\u003e\u003c/p\u003e\n\u003ch3 id=\"分解程序\"\u003e分解程序\u003c/h3\u003e\n\u003cp\u003eDijkstra希望使用数学推导方法对程序进行推理证明：让程序就成为了一种欧几里得结构，这样可以用一些已经证明的结构串联起新的程序，从而进一步推导整个程序的正确性。\u003c/p\u003e\n\u003cp\u003e他还发现，如果程序中包含大量的goto，那么程序会变得难以分解，而goto语句的作用完全可以依靠分支和循环来完成。\u003c/p\u003e\n\u003cp\u003e这样，结构化编程范式表明，程序可以进行降解拆分，一个大型问题拆分为一系列高级函数的组合，而这些高级函数各自又可以继续被拆分为一系列低级函数，如此无限递归。更重要的是，每个被拆分出来的函数也都可以用结构化编程范式来书写。\u003c/p\u003e\n\u003cp\u003e但是，这种形式化证明的编程方式没有成为主流，科学证明法是目前使用较多的方法。\u003c/p\u003e\n\u003ch3 id=\"科学证明法\"\u003e科学证明法\u003c/h3\u003e\n\u003cp\u003e科学理论和科学定律可以被证伪，但是没有办法被证明，类似的，程序只能测试证伪，不能证明，即“测试只能展示Bug的存在，并不能证明不存在Bug”。因此，利用科学证明法，结构化编程范式就可以促使我们先将一段程序递归降解为一系列可证明的小函数，然后再编写相关的\u003cstrong\u003e测试\u003c/strong\u003e来试图证明这些函数是错误的。如果这些测试无法证伪这些函数，那么我们就可以认为这些函数是足够正确的，进而推导整个程序是正确的。\u003c/p\u003e\n\u003ch2 id=\"面向对象编程范式\"\u003e面向对象编程范式\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e面向对象编程对程序控制权的间接转移进行了限制和规范。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e具体来说，面向对象编程凡事使用\u003cstrong\u003e多态特性\u003c/strong\u003e限制了函数指针的使用。这可以理解为函数指针只能进行有限制的指向，比如java中的多态一般出现在有继承关系的两个类的对象之间。\u003c/p\u003e\n\u003cp\u003e作者也认为多态是OOP的最大特性，利用多态可以做到\u003cstrong\u003e依赖反转\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003e依赖反转即引入接口，完全控制系统中所有源代码的依赖关系，而不需要收到系统控制流的制约。\u003c/p\u003e\n\u003cp\u003e依赖反转保证了我们可以对系统进行插件式的开发，如将web UI和数据库与业务逻辑之间的依赖进行反转，可以保证主业务逻辑与UI和数据库的解耦，这样UI和数据库就成了主业务逻辑的插件。\u003c/p\u003e\n\u003cp\u003e面向对象编程就是以多态为手段来对源代码中的依赖关系进行控制的能力，这种能力让软件架构师可以构建出某种插件式架构，让高层策略性组件与底层实现性组件相分离，底层组件可以被编译成插件，实现独立于高层组件的开发和部署。\u003c/p\u003e\n\u003ch2 id=\"函数式编程范式\"\u003e函数式编程范式\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e函数式编程对程序中的赋值进行了限制和规范。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e换句话说，函数式编程语言中变量是不可变的。\u003c/p\u003e\n\u003cp\u003e作者有以下的观点，这一段话来自原文：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e“所有的竞争问题、死锁问题、并发更新问题都是由可变变量导致的。如果变量永远不会被更改，那就不可能产生竞争或者并发更新问题。如果锁状态是不可变的，那就永远不会产生死锁问题\u0026quot;\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e如果不考虑储存器与处理器的速度限制，那么不可变性是可行的，但实际上我们必须考虑这些因素，因此可变性只能在一定程度上可行，需要让不可变性在一定程度上可行需要完成\u003cstrong\u003e可变性的隔离\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3 id=\"可变性的隔离\"\u003e可变性的隔离\u003c/h3\u003e\n\u003cp\u003e可变性隔离的一种常见方式是将应用程序，或者是应用程序的内部服务进行切分，\u003cstrong\u003e划分为可变的和不可变的两种组件\u003c/strong\u003e。不可变组件用纯函数的方式来执行任务，期间不更改任何状态。这些不可变的组件将通过与一个或多个非函数式组件（即可变组件）通信的方式来修改变量状态。\u003c/p\u003e\n\u003cp\u003e一个例子是GIT版本管理工具。它通过移动指针来记录文件的变化：增删改，但实际上文件并没有被真正的修改和删除，只存在增加和检索查询两种情况，这不就是不可变性的一个例子吗。\u003c/p\u003e\n\u003cp\u003e同时，mysql中的事务管理、事务性内存的工作也都运用了这个思想。\u003c/p\u003e\n\u003ch2 id=\"总结\"\u003e总结\u003c/h2\u003e\n\u003cp\u003e三种编程范式与软件架构具有密切的关系：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e多态是我们跨越边界的手段；\u003c/li\u003e\n\u003cli\u003e函数式编程是我们规范和限制数据存放位置与访问权限的手段；\u003c/li\u003e\n\u003cli\u003e结构化编程则是个模块的实现基础；\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e三种编程范式与软件架构的三大关注重点不谋而合：\u003cstrong\u003e组件独立性\u003c/strong\u003e（面向对象）、\u003cstrong\u003e数据管理\u003c/strong\u003e（函数式）以及功能性（结构）。\u003c/p\u003e\n\u003ch2 id=\"再次思考\"\u003e再次思考\u003c/h2\u003e\n\u003cp\u003e三种编程范式都对程序员提出了新的\u003cstrong\u003e限制\u003c/strong\u003e。每个范式都约束了某种编写代码的方式，没有一个编程范式是在增加新能力。也就是说，编程范式带来的是——什么不应该做。\u003c/p\u003e\n\u003cp\u003e（第二篇完）\u003c/p\u003e\n","description":"再读整洁架构之道（二）","image":"/blogimages/arh2.png","permalink":"https://tommycheese.github.io/blogs/%E5%86%8D%E8%AF%BB%E6%95%B4%E6%B4%81%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%81%93%E4%BA%8C/","title":"再读整洁架构之道（二）"},{"content":"\u003ch2 id=\"前记\"\u003e前记\u003c/h2\u003e\n\u003cp\u003e为什么是再读？因为在这之前笔者已经阅读过一遍架构之道这本书，但当时缺乏项目的锻炼和试错，总觉得读的不深，终于有幸在工作期间接触到了一些项目和需求，更幸运的是项目组在开发时采用的架构正好是整洁架构，详细的说，是事件驱动开发DDD+整洁架构，关于DDD的详细内容将会在之后讨论，笔者就重新阅读了这本书📚，收获颇丰，因此这一个系列，我准备用自己的拙见描述一下整洁架构，更准确的说，应该是是读书笔记，以兹同仁。\u003c/p\u003e\n\u003cp\u003e这本书的详细地址为：\u003ca href=\"https://weread.qq.com/web/bookDetail/480322f072021a3248038c8\"\u003e架构整洁之道-罗伯特 C. 马丁-微信读书 (qq.com)\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e本系列会以图书的章节组织作为思路，跟随作者的脚步逐渐深入，同时，由于是再读，所以不可避免的也会穿插一些图书中其他部分的内容，所以，如果你在阅读时发现了一些难于理解或者没听说过的内容，那它大概率是在之后章节中的内容。\u003c/p\u003e\n\u003cp\u003e让我们开始吧。\u003c/p\u003e\n\u003ch2 id=\"设计与架构的含义\"\u003e设计与架构的含义\u003c/h2\u003e\n\u003cp\u003e设计与架构，本质上并没有区别，底层设计细节和顶层架构信息共同定义了软件系统。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e软件架构的终极目标是用最小的人力成本来满足构建和维护系统的需求\u003c/strong\u003e，因此成本可以评估一个软件架构设计的优劣。\u003c/p\u003e\n\u003cp\u003e没有经过设计、匆匆构建的系统可能成为\u003cstrong\u003e乱麻系统\u003c/strong\u003e，乱麻系统在构建过程中被长期忽视代码质量和设计结构优化。认真设计软件架构可以在一定程度上避免系统成为乱麻系统，从而降低成本。\u003c/p\u003e\n\u003cp\u003e软件开发具有两个核心特点：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e要想跑得快，要先跑得稳；\u003c/li\u003e\n\u003cli\u003e过度自信只会使得重构设计陷入和原项目一样的困局。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"两个价值维度\"\u003e两个价值维度\u003c/h2\u003e\n\u003cp\u003e软件系统包含两种价值：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e行为价值：让机器按照某种指定方式运转，给系统的使用者创造或者提高利润；\u003c/li\u003e\n\u003cli\u003e架构价值：软件要够灵活，更改软件的成本要做到与需求的范畴相关，与形状无关。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e怎么理解需求的范畴与形状？\n笔者自己理解范畴即需求大致的范围和所属\u003cstrong\u003e领域\u003c/strong\u003e，而形状指需求的细节内容。\u003c/p\u003e\n\u003cp\u003e那么哪个价值维度更重要呢？\n作者认为架构价值比行为价值更重要，因为：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e如果某程序可以正常工作，但是无法修改，那么当需求变更的时候它就不再能够正常工作了，我们也无法通过修改让它能继续正常工作。因此，这个程序的价值将成为0；\u003c/li\u003e\n\u003cli\u003e如果某程序目前无法正常工作，但是我们可以很容易地修改它，那么将它改好，并且随着需求变化不停地修改它，都应该是很容易的事。因此，这个程序会持续产生价值。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e业务部门与研发部门经常犯的共同错误是没有把真正紧急并且重要的功能和紧急但是不重要的功能分开，结果就是重要的系统架构问题让位给了不重要的系统行为功能。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e平衡系统架构的重要性与功能的紧急程度这件事，是软件研发人员自己的职责\u003c/strong\u003e。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e笔者注：同时，即便同样是研发人员，不同的小组也会存在类似问题，正如某些前端部门认为后台只需要提供一系列接口很容易，而不知道良好设计的重要性。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"为好的软件架构持续斗争\"\u003e为好的软件架构持续斗争\u003c/h3\u003e\n\u003cp\u003e如果忽视软件架构的价值，系统将会变得越来越难以维护，终会有一天，系统将会变得再也无法修改。如果系统变成了这个样子，那么说明软件开发团队没有和需求方做足够的抗争，没有完成自己应尽的职责。\u003c/p\u003e\n","description":"再读整洁架构之道（一）","image":"/blogimages/arh1.png","permalink":"https://tommycheese.github.io/blogs/%E5%86%8D%E8%AF%BB%E6%95%B4%E6%B4%81%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%81%93%E4%B8%80/","title":"再读整洁架构之道（一）"},{"content":"\u003ch3 id=\"问题简述\"\u003e问题简述\u003c/h3\u003e\n\u003cp\u003e在日常的模型开发、训练过程中我们经常会遇到这样的现象：在现有的开源项目或者论文复现中，多数模型使用Pytorch设计、开发和训练推理，当我们需要使用MindSpore框架进行模型开发时，会遇到以下两个问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e模型使用Pytorch编码；\u003c/li\u003e\n\u003cli\u003ePytorch模型训练后保存的参数无法被MindSpore模型直接加载。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e对于第一个问题，我们可以根据昇思官方提供的文档：\u003ca href=\"https://www.mindspore.cn/docs/zh-CN/r2.1/migration_guide/typical_api_comparision.html#%E4%B8%8Epytorch%E5%85%B8%E5%9E%8B%E6%8E%A5%E5%8F%A3%E5%8C%BA%E5%88%AB\"\u003e与Pytorch典型区别\u003c/a\u003e和\u003ca href=\"https://www.mindspore.cn/docs/zh-CN/r2.1/note/api_mapping/pytorch_api_mapping.html#pytorch%E4%B8%8Emindspore-api%E6%98%A0%E5%B0%84%E8%A1%A8\"\u003ePyTorch与MindSpore API映射表\u003c/a\u003e来完成模型的迁移；\u003c/p\u003e\n\u003cp\u003e对于模型参数的转换，在最新的MindSpore版本中MindConverter不再支持，因此可以考虑针对模型参数，我们进行\u003cstrong\u003e手动的转换\u003c/strong\u003e，将Pytorch模型参数转换为MindSpore能识别的格式后，再进行加载。\u003c/p\u003e\n\u003ch3 id=\"解决方案\"\u003e解决方案\u003c/h3\u003e\n\u003cp\u003e模型的编码转换不再赘述。\u003c/p\u003e\n\u003cp\u003e参数转换主要思路如下：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e使用Pytorch加载Pytorch模型，并取得模型参数prams_torch；\u003c/li\u003e\n\u003cli\u003e使用MindSpore加载MindSpore模型，并取得模型参数prams_ms；\u003c/li\u003e\n\u003cli\u003e将Pytorch模型的参数名和MindSpore模型参数名一一对应（有的话）；\u003c/li\u003e\n\u003cli\u003e建立torch_2_ms键名映射表，使用键名映射表将Pytorch模型参数值加载到MindSpore参数名对应的位置上；\u003c/li\u003e\n\u003cli\u003e使用MindSpore加载参数。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"案例分析\"\u003e案例分析\u003c/h3\u003e\n\u003cp\u003e不同模型的模块不相同，参数类型也不尽相同，此处我们以一个网络举例，说明转换的基本思路，不同的模型其转换思路是类似的。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/1905.11946\"\u003eEfficientNet\u003c/a\u003e是谷歌于2019年发表的文章，详细网络架构可查看文章描述，此处我们以\u003cstrong\u003eEfficientNet+FC\u003c/strong\u003e全连接层的模型为例，探讨如何进行网络模型参数的转换。\u003c/p\u003e\n\u003ch4 id=\"使用pytorch加载pytorch模型并取得模型参数prams_torch\"\u003e使用Pytorch加载Pytorch模型，并取得模型参数prams_torch\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e torch\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e test.efficientnet_pytorch.model \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e EfficientNet \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e EN_pytorch\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e pandas \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e pd\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epytorch_model \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e EN_pytorch\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efrom_name(cfg[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;model\u0026#39;\u003c/span\u003e], override_params\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e{\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;num_classes\u0026#39;\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e})\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epytorch_model\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecuda()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epytorch_weights_dict \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pytorch_model\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estate_dict()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eparam_torch \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pytorch_weights_dict\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeys()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eparam_torch_lst \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pd\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eDataFrame(param_torch)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eparam_torch_lst\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eto_csv(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;param_torch.csv\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e步骤结束后，我们就将pytorch的模型参数存到了param_torch.csv下，观察数据：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003ekeys\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e0\u003c/td\u003e\n\u003ctd\u003e_conv_stem.weight\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e_bn0.weight\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003ctd\u003e_bn0.bias\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e3\u003c/td\u003e\n\u003ctd\u003e_bn0.running_mean\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e4\u003c/td\u003e\n\u003ctd\u003e_bn0.running_var\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003ctd\u003e_bn0.num_batches_tracked\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e6\u003c/td\u003e\n\u003ctd\u003e_blocks.0._depthwise_conv.weight\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e7\u003c/td\u003e\n\u003ctd\u003e_blocks.0._bn1.weight\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e8\u003c/td\u003e\n\u003ctd\u003e_blocks.0._bn1.bias\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e9\u003c/td\u003e\n\u003ctd\u003e_blocks.0._bn1.running_mean\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e10\u003c/td\u003e\n\u003ctd\u003e_blocks.0._bn1.running_var\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch4 id=\"使用mindspore加载mindspore模型并取得模型参数prams_ms\"\u003e使用MindSpore加载MindSpore模型，并取得模型参数prams_ms\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e mindspore \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e ms\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e test.efficientnet_mindspore.model \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e EfficientNet \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e EN_ms\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e pandas \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e pd\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003emindspore_model \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e EN_ms\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efrom_name(cfg[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;model\u0026#39;\u003c/span\u003e], override_params\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e{\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;num_classes\u0026#39;\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e})\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprams_ms \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e mindspore_model\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eparameters_dict()\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeys()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprams_ms_lst \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pd\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eDataFrame(prams_ms)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprams_ms_lst\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eto_csv(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;prams_ms.csv\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e步骤结束后，我们就将MindSpore的模型参数存到了prams_ms.csv下，观察数据：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003ekeys\u003c/th\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e0\u003c/td\u003e\n\u003ctd\u003e_conv_stem.weight\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e_bn0.moving_mean\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003ctd\u003e_bn0.moving_variance\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e3\u003c/td\u003e\n\u003ctd\u003e_bn0.gamma\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e4\u003c/td\u003e\n\u003ctd\u003e_bn0.beta\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003ctd\u003e0._depthwise_conv.weight\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e6\u003c/td\u003e\n\u003ctd\u003e0._bn1.moving_mean\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e7\u003c/td\u003e\n\u003ctd\u003e0._bn1.moving_variance\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e8\u003c/td\u003e\n\u003ctd\u003e0._bn1.gamma\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e9\u003c/td\u003e\n\u003ctd\u003e0._bn1.beta\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e10\u003c/td\u003e\n\u003ctd\u003e0._se_reduce.weight\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch4 id=\"将pytorch模型的参数名和mindspore模型参数名一一对应\"\u003e将Pytorch模型的参数名和MindSpore模型参数名一一对应\u003c/h4\u003e\n\u003cp\u003e自此我们就得到了MindSpore和Pytorch各自的参数键名表（附在附件区域），随后观察二者参数命名上的差异，可以发现固定的规律，以下述几个方面为例：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBatch Normalization：\n\u003cul\u003e\n\u003cli\u003e权重：weight|bias——gamma|beta；\u003c/li\u003e\n\u003cli\u003e移动加权和方差：running_mean|running_var——moving_mean|moving_variance；\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e自定义blocks：pytorch带前置的_blocks.；\u003c/li\u003e\n\u003cli\u003e其他\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"键名映射表\"\u003e键名映射表\u003c/h4\u003e\n\u003cp\u003e这样就可以根据规律写出一个Python脚本来完成键名的转化，并生成键名映射表：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003ePytorch\u003c/th\u003e\n\u003cth\u003emindspore\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e_conv_stem.weight\u003c/td\u003e\n\u003ctd\u003e_conv_stem.weight\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_bn0.weight\u003c/td\u003e\n\u003ctd\u003e_bn0.gamma\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_bn0.bias\u003c/td\u003e\n\u003ctd\u003e_bn0.beta\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_bn0.running_mean\u003c/td\u003e\n\u003ctd\u003e_bn0.moving_mean\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_bn0.running_var\u003c/td\u003e\n\u003ctd\u003e_bn0.moving_variance\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_blocks.0._depthwise_conv.weight\u003c/td\u003e\n\u003ctd\u003e0._depthwise_conv.weight\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_blocks.0._bn1.weight\u003c/td\u003e\n\u003ctd\u003e0._bn1.gamma\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_blocks.0._bn1.bias\u003c/td\u003e\n\u003ctd\u003e0._bn1.beta\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_blocks.0._bn1.running_mean\u003c/td\u003e\n\u003ctd\u003e0._bn1.moving_mean\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_blocks.0._bn1.running_var\u003c/td\u003e\n\u003ctd\u003e0._bn1.moving_variance\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_blocks.0._se_reduce.weight\u003c/td\u003e\n\u003ctd\u003e0._se_reduce.weight\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e随后在Pytorch的权重字典中，按照对应文件的Pytorch_key取出权重值，随后使用mindspore.Parameter进行封装，添加到mindspore.key对应的权值中去：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e ms_param_lst\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003evalues:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    ms_key \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e i\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    pt_key \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e param_mapping[ms_key]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    pt_val \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pt_values_dict[pt_key]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003enot\u003c/span\u003e isinstance(pt_val, np\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003endarray):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        pt_val \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pt_val\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecpu()\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003enumpy()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    ms_val \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e Parameter(pt_val, ms_key)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    print(ms_val)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    ms_values_dict[ms_key] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e ms_val\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch4 id=\"使用mindspore加载参数\"\u003e使用MindSpore加载参数\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eload_param_into_net(mindspore_model, ms_values_dict)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e此时，参数应该就可以被MindSpore接受了。\u003c/p\u003e\n\u003ch3 id=\"whats-more\"\u003eWhat\u0026rsquo;s more\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e在参数值的存储过程中，要注意Pytorch和MindSpore参数精度的差异；\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e（完）\u003c/p\u003e\n","description":"本文描述了Pytorch模型及参数与MindSpore模型、参数转换执行时的问题，同时给出了一种可行的解决方案完成Pytorch-\u003eMindSpore的转换。","image":"/blogimages/p2m.png","permalink":"https://tommycheese.github.io/blogs/%E5%AE%9E%E7%94%A8%E5%B9%B2%E8%B4%A7%E5%A6%82%E4%BD%95%E6%8A%8Apytorch%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E5%8A%A0%E8%BD%BD%E5%88%B0mindspore%E6%A8%A1%E5%9E%8B/","title":"实用干货：如何把Pytorch模型参数加载到MindSpore模型？"},{"content":"\u003cp\u003e本文讨论研究梯度下降法的一个有力的数学工具：海森矩阵。在讨论海森矩阵之前，需要首先了解梯度和雅克比矩阵的基本概念。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e:star:本文假设读者已经熟悉梯度下降法和简单的数值分析、线性代数知识\n\u003ca href=\"https://tommycheese.github.io/blogs/%E6%A2%AF%E5%BA%A6%E4%B9%8B%E4%B8%8Ahessian-%E7%9F%A9%E9%98%B5/\"\u003e原文链接\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"梯度雅克比矩阵\"\u003e梯度、雅克比矩阵\u003c/h2\u003e\n\u003cp\u003e梯度下降算法需要当前函数点的导数信息，当此函数点包含多个方向时，梯度是包含所有方向的（偏）导数向量。\u003c/p\u003e\n\u003cp\u003e上述情况对应于\u003cstrong\u003e输出为一个\u003c/strong\u003e的情况，当函数的输出也为一个向量时，我们需要把输出向量的每一个元素对于多个输入的梯度\u003cstrong\u003e罗列在一起\u003c/strong\u003e，罗列形成的矩阵就是\u003cstrong\u003e雅克比矩阵（Jacobian Matrix）\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e举例说明：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e若函数$f$接受三个输入$x1、x2、x3$，产生一个输出$y$，则其梯度为：\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e$$\n\\begin{equation}\nGrad = [\\frac{\\partial y}{\\partial x_1}, \\frac{\\partial y}{\\partial x_2}, \\frac{\\partial y}{\\partial x_3}]\n\\end{equation}\n$$\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e若函数$f2$接受三个输入$x1、x2、x3$，产生三个输出$y1、y2、y3$，则其雅克比矩阵为：\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e$$\n\\begin{equation}\nJacobian  = \\begin{bmatrix}\n\\frac{\\partial y_1}{\\partial x_1} \u0026amp;  \\frac{\\partial y_1}{\\partial x_2}\u0026amp;\\frac{\\partial y_1}{\\partial x_3} \\\n\\frac{\\partial y_2}{\\partial x_1} \u0026amp;  \\frac{\\partial y_2}{\\partial x_2}\u0026amp;\\frac{\\partial y_2}{\\partial x_3} \\\n\\frac{\\partial y_3}{\\partial x_1} \u0026amp;  \\frac{\\partial y_3}{\\partial x_2}\u0026amp;\\frac{\\partial y_3}{\\partial x_3}\n\\end{bmatrix}\n\\end{equation}\n$$\u003c/p\u003e\n\u003cp\u003e利用二阶导数，我们可以知道关于函数在特定方向 $d$ 上的凹凸信息，利用凹凸信息可以在一定程度上预判梯度下降法的表现效果。如果在特定方向 $d$ 上：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e二阶导数为正，则函数在方向$d$上一阶导数增加，函数值下降更慢；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e二阶导数为负，则函数在方向$d$上一阶导数减少，函数值下降更快；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e二阶导数为零，则函数在方向$d$上一阶导数不变，函数值匀速下降；\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e:star:注意在梯度下降法中是对损失函数进行下降，因此需要使用减函数来分析函数中\u003cstrong\u003e某一小段\u003c/strong\u003e（经常使用二次函数的减半部近似：二阶泰勒展开、牛顿法）中的导数变化情况；\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"海森矩阵\"\u003e海森矩阵\u003c/h2\u003e\n\u003cp\u003e和雅克比矩阵类似，\u003cstrong\u003e海森矩阵（Hessian 矩阵）\u003cstrong\u003e可以包含函数中二阶导的信息：\n$$\nHessian   = \\begin{bmatrix}\n\\frac{\\partial^2y}{\\partial x_1\\partial x_1} \u0026amp;  \\frac{\\partial^2y}{\\partial x_1\\partial x_2}\u0026amp;\\frac{\\partial^2y}{\\partial x_1\\partial x_3} \\\n\\frac{\\partial^2y}{\\partial x_2\\partial x_1} \u0026amp;  \\frac{\\partial^2y}{\\partial x_2\\partial x_2}\u0026amp;\\frac{\\partial^2y}{\\partial x_2\\partial x_3} \\\n\\frac{\\partial^2y}{\\partial x_3\\partial x_1} \u0026amp;  \\frac{\\partial^2y}{\\partial x_3\\partial x_2}\u0026amp;\\frac{\\partial^2y}{\\partial x_3\\partial x_3}\n\\end{bmatrix}\n$$\n同时由于二阶导数计算顺序的可交换性，即 $\\frac{\\partial^2y}{\\partial x_1\\partial x_2}=\\frac{\\partial^2y}{\\partial x_2\\partial x_1}$，因此\u003c/strong\u003e海森矩阵是一个对称矩阵\u003c/strong\u003e，对于对称矩阵我们可以使用\u003cstrong\u003e特征分解\u003c/strong\u003e来研究特征值和二阶导数的关系，便于我们快速获得某个方向的二阶导数。\u003c/p\u003e\n\u003cp\u003e针对于特定方向d，已知此方向的二阶导数可以写成 $d^THd$ ，则：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e:link: \u003ca href=\"https://blog.csdn.net/weixin_42397505/article/details/112066943\"\u003e基于Hessian矩阵的二阶方向导数与性质_Hi 喀什噶尔的胡杨的博客-CSDN博客_二阶方向导数\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e若d是H对应特征值λ的特征向量：\u003c/p\u003e\n\u003cp\u003e因为d为对应λ的特征向量（以下简称特征向量），则据定义有：\n$$\nHd = \\lambda d\\\n\\Rightarrow  d^THd=d^T\\lambda d = \\lambda d^Td=\\lambda    \\ \\ \\ 对称矩阵d^T = d^-\n$$\u003c/p\u003e\n\u003cp\u003e因此特征向量对应的特征值λ即为此方向的二阶导数；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e若d为其他方向：设$e_i$为$H$对应特征值$\\lambda_i$的特征向量，由上可知，\n$$\n\\lambda_i=e_i^THe_i\n$$\n可知任何一个方向$d=\\sum_i^mt_ie_i$为特征向量的线性组合，其中m为特征值个数，$t_i$为第$i$个特征向量的加权数，则：\n$$\nd^THd=(\\sum_i^mt_ie_i)^TH(\\sum_i^mt_ie_i)=\\sum_i^mt_ie_i^THt_ie_i=\\sum_i^mt_i^2\\lambda_i\n$$\n因此任意非特征向量方向的二阶导数是所有特征值的加权和，特别的，此时的加权和是一个椭球体，在二维的特征值情况下，二阶导数是一个椭圆，椭圆方程为：\n$$\ny=\\frac{\\lambda_1}{\\frac{1}{t_1^2}}+\\frac{\\lambda_2}{\\frac{1}{t_2^2}}\n$$\n\u003cimg src=\"https://img-blog.csdnimg.cn/img_convert/bb30779d25d486346799cb0fce7d34ad.png#pic_center\" alt=\"在这里插入图片描述\"\u003e\u003c/p\u003e\n\u003cp\u003e由图可知，最大二阶导数由最大特征值决定（长半轴），而最小二阶导数由最小特征值决定（短半轴）。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"海森矩阵应用\"\u003e海森矩阵应用\u003c/h2\u003e\n\u003cp\u003e在弄清海森矩阵的基本定义后，就可以使用海森矩阵的一些性质来分析优化方法中的一些问题了。如确定局部最大点、局部最小点和鞍点、确定学习率、以及使用病态条件来确定梯度下降的表现等，同时我们还可以利用Hessian矩阵来实现\u003cstrong\u003e牛顿法\u003c/strong\u003e这种优化算法，。\u003c/p\u003e\n\u003cp\u003e（本节完）\u003c/p\u003e\n","description":"本文讨论研究梯度下降法的一个有力的数学工具：海森矩阵。","image":"/blogimages/hessen.png","permalink":"https://tommycheese.github.io/blogs/h/","title":"梯度之上：Hessian 矩阵"},{"content":"","description":"🌏","image":null,"permalink":"https://tommycheese.github.io/gallery/","title":"探索|Explore"}]