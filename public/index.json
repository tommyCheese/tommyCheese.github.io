[{"content":"\u003ch3 id=\"问题简述\"\u003e问题简述\u003c/h3\u003e\n\u003cp\u003e在日常的模型开发、训练过程中我们经常会遇到这样的现象：在现有的开源项目或者论文复现中，多数模型使用Pytorch设计、开发和训练推理，当我们需要使用MindSpore框架进行模型开发时，会遇到以下两个问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e模型使用Pytorch编码；\u003c/li\u003e\n\u003cli\u003ePytorch模型训练后保存的参数无法被MindSpore模型直接加载。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e对于第一个问题，我们可以根据昇思官方提供的文档：\u003ca href=\"https://www.mindspore.cn/docs/zh-CN/r2.1/migration_guide/typical_api_comparision.html#%E4%B8%8Epytorch%E5%85%B8%E5%9E%8B%E6%8E%A5%E5%8F%A3%E5%8C%BA%E5%88%AB\"\u003e与Pytorch典型区别\u003c/a\u003e和\u003ca href=\"https://www.mindspore.cn/docs/zh-CN/r2.1/note/api_mapping/pytorch_api_mapping.html#pytorch%E4%B8%8Emindspore-api%E6%98%A0%E5%B0%84%E8%A1%A8\"\u003ePyTorch与MindSpore API映射表\u003c/a\u003e来完成模型的迁移；\u003c/p\u003e\n\u003cp\u003e对于模型参数的转换，在最新的MindSpore版本中MindConverter不再支持，因此可以考虑针对模型参数，我们进行\u003cstrong\u003e手动的转换\u003c/strong\u003e，将Pytorch模型参数转换为MindSpore能识别的格式后，再进行加载。\u003c/p\u003e\n\u003ch3 id=\"解决方案\"\u003e解决方案\u003c/h3\u003e\n\u003cp\u003e模型的编码转换不再赘述。\u003c/p\u003e\n\u003cp\u003e参数转换主要思路如下：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e使用Pytorch加载Pytorch模型，并取得模型参数prams_torch；\u003c/li\u003e\n\u003cli\u003e使用MindSpore加载MindSpore模型，并取得模型参数prams_ms；\u003c/li\u003e\n\u003cli\u003e将Pytorch模型的参数名和MindSpore模型参数名一一对应（有的话）；\u003c/li\u003e\n\u003cli\u003e建立torch_2_ms键名映射表，使用键名映射表将Pytorch模型参数值加载到MindSpore参数名对应的位置上；\u003c/li\u003e\n\u003cli\u003e使用MindSpore加载参数。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"案例分析\"\u003e案例分析\u003c/h3\u003e\n\u003cp\u003e不同模型的模块不相同，参数类型也不尽相同，此处我们以一个网络举例，说明转换的基本思路，不同的模型其转换思路是类似的。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/1905.11946\"\u003eEfficientNet\u003c/a\u003e是谷歌于2019年发表的文章，详细网络架构可查看文章描述，此处我们以\u003cstrong\u003eEfficientNet+FC\u003c/strong\u003e全连接层的模型为例，探讨如何进行网络模型参数的转换。\u003c/p\u003e\n\u003ch4 id=\"使用pytorch加载pytorch模型并取得模型参数prams_torch\"\u003e使用Pytorch加载Pytorch模型，并取得模型参数prams_torch\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e torch\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e test.efficientnet_pytorch.model \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e EfficientNet \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e EN_pytorch\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e pandas \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e pd\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epytorch_model \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e EN_pytorch\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efrom_name(cfg[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;model\u0026#39;\u003c/span\u003e], override_params\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e{\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;num_classes\u0026#39;\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e})\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epytorch_model\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecuda()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epytorch_weights_dict \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pytorch_model\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estate_dict()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eparam_torch \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pytorch_weights_dict\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeys()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eparam_torch_lst \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pd\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eDataFrame(param_torch)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eparam_torch_lst\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eto_csv(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;param_torch.csv\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e步骤结束后，我们就将pytorch的模型参数存到了param_torch.csv下，观察数据：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003ekeys\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e0\u003c/td\u003e\n\u003ctd\u003e_conv_stem.weight\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e_bn0.weight\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003ctd\u003e_bn0.bias\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e3\u003c/td\u003e\n\u003ctd\u003e_bn0.running_mean\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e4\u003c/td\u003e\n\u003ctd\u003e_bn0.running_var\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003ctd\u003e_bn0.num_batches_tracked\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e6\u003c/td\u003e\n\u003ctd\u003e_blocks.0._depthwise_conv.weight\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e7\u003c/td\u003e\n\u003ctd\u003e_blocks.0._bn1.weight\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e8\u003c/td\u003e\n\u003ctd\u003e_blocks.0._bn1.bias\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e9\u003c/td\u003e\n\u003ctd\u003e_blocks.0._bn1.running_mean\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e10\u003c/td\u003e\n\u003ctd\u003e_blocks.0._bn1.running_var\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch4 id=\"使用mindspore加载mindspore模型并取得模型参数prams_ms\"\u003e使用MindSpore加载MindSpore模型，并取得模型参数prams_ms\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e mindspore \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e ms\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e test.efficientnet_mindspore.model \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e EfficientNet \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e EN_ms\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e pandas \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e pd\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003emindspore_model \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e EN_ms\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efrom_name(cfg[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;model\u0026#39;\u003c/span\u003e], override_params\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e{\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;num_classes\u0026#39;\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e})\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprams_ms \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e mindspore_model\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eparameters_dict()\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeys()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprams_ms_lst \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pd\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eDataFrame(prams_ms)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprams_ms_lst\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eto_csv(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;prams_ms.csv\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e步骤结束后，我们就将MindSpore的模型参数存到了prams_ms.csv下，观察数据：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003ekeys\u003c/th\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e0\u003c/td\u003e\n\u003ctd\u003e_conv_stem.weight\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e_bn0.moving_mean\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003ctd\u003e_bn0.moving_variance\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e3\u003c/td\u003e\n\u003ctd\u003e_bn0.gamma\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e4\u003c/td\u003e\n\u003ctd\u003e_bn0.beta\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003ctd\u003e0._depthwise_conv.weight\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e6\u003c/td\u003e\n\u003ctd\u003e0._bn1.moving_mean\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e7\u003c/td\u003e\n\u003ctd\u003e0._bn1.moving_variance\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e8\u003c/td\u003e\n\u003ctd\u003e0._bn1.gamma\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e9\u003c/td\u003e\n\u003ctd\u003e0._bn1.beta\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e10\u003c/td\u003e\n\u003ctd\u003e0._se_reduce.weight\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch4 id=\"将pytorch模型的参数名和mindspore模型参数名一一对应\"\u003e将Pytorch模型的参数名和MindSpore模型参数名一一对应\u003c/h4\u003e\n\u003cp\u003e自此我们就得到了MindSpore和Pytorch各自的参数键名表（附在附件区域），随后观察二者参数命名上的差异，可以发现固定的规律，以下述几个方面为例：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBatch Normalization：\n\u003cul\u003e\n\u003cli\u003e权重：weight|bias——gamma|beta；\u003c/li\u003e\n\u003cli\u003e移动加权和方差：running_mean|running_var——moving_mean|moving_variance；\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e自定义blocks：pytorch带前置的_blocks.；\u003c/li\u003e\n\u003cli\u003e其他\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"键名映射表\"\u003e键名映射表\u003c/h4\u003e\n\u003cp\u003e这样就可以根据规律写出一个Python脚本来完成键名的转化，并生成键名映射表：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003ePytorch\u003c/th\u003e\n\u003cth\u003emindspore\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e_conv_stem.weight\u003c/td\u003e\n\u003ctd\u003e_conv_stem.weight\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_bn0.weight\u003c/td\u003e\n\u003ctd\u003e_bn0.gamma\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_bn0.bias\u003c/td\u003e\n\u003ctd\u003e_bn0.beta\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_bn0.running_mean\u003c/td\u003e\n\u003ctd\u003e_bn0.moving_mean\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_bn0.running_var\u003c/td\u003e\n\u003ctd\u003e_bn0.moving_variance\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_blocks.0._depthwise_conv.weight\u003c/td\u003e\n\u003ctd\u003e0._depthwise_conv.weight\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_blocks.0._bn1.weight\u003c/td\u003e\n\u003ctd\u003e0._bn1.gamma\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_blocks.0._bn1.bias\u003c/td\u003e\n\u003ctd\u003e0._bn1.beta\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_blocks.0._bn1.running_mean\u003c/td\u003e\n\u003ctd\u003e0._bn1.moving_mean\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_blocks.0._bn1.running_var\u003c/td\u003e\n\u003ctd\u003e0._bn1.moving_variance\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e_blocks.0._se_reduce.weight\u003c/td\u003e\n\u003ctd\u003e0._se_reduce.weight\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e随后在Pytorch的权重字典中，按照对应文件的Pytorch_key取出权重值，随后使用mindspore.Parameter进行封装，添加到mindspore.key对应的权值中去：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e ms_param_lst\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003evalues:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    ms_key \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e i\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    pt_key \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e param_mapping[ms_key]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    pt_val \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pt_values_dict[pt_key]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003enot\u003c/span\u003e isinstance(pt_val, np\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003endarray):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        pt_val \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pt_val\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecpu()\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003enumpy()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    ms_val \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e Parameter(pt_val, ms_key)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    print(ms_val)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    ms_values_dict[ms_key] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e ms_val\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch4 id=\"使用mindspore加载参数\"\u003e使用MindSpore加载参数\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eload_param_into_net(mindspore_model, ms_values_dict)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e此时，参数应该就可以被MindSpore接受了。\u003c/p\u003e\n\u003ch3 id=\"whats-more\"\u003eWhat\u0026rsquo;s more\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e在参数值的存储过程中，要注意Pytorch和MindSpore参数精度的差异；\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e（完）\u003c/p\u003e\n","description":"本文描述了Pytorch模型及参数与MindSpore模型、参数转换执行时的问题，同时给出了一种可行的解决方案完成Pytorch-\u003eMindSpore的转换。","image":"/blogimages/p2m.png","permalink":"https://tommycheese.github.io/blogs/%E5%AE%9E%E7%94%A8%E5%B9%B2%E8%B4%A7%E5%A6%82%E4%BD%95%E6%8A%8Apytorch%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E5%8A%A0%E8%BD%BD%E5%88%B0mindspore%E6%A8%A1%E5%9E%8B/","title":"实用干货：如何把Pytorch模型参数加载到MindSpore模型？"},{"content":"\u003cp\u003e本文讨论研究梯度下降法的一个有力的数学工具：海森矩阵。在讨论海森矩阵之前，需要首先了解梯度和雅克比矩阵的基本概念。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e:star:本文假设读者已经熟悉梯度下降法和简单的数值分析、线性代数知识\n\u003ca href=\"https://tommycheese.github.io/blogs/%E6%A2%AF%E5%BA%A6%E4%B9%8B%E4%B8%8Ahessian-%E7%9F%A9%E9%98%B5/\"\u003e原文链接\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"梯度雅克比矩阵\"\u003e梯度、雅克比矩阵\u003c/h2\u003e\n\u003cp\u003e梯度下降算法需要当前函数点的导数信息，当此函数点包含多个方向时，梯度是包含所有方向的（偏）导数向量。\u003c/p\u003e\n\u003cp\u003e上述情况对应于\u003cstrong\u003e输出为一个\u003c/strong\u003e的情况，当函数的输出也为一个向量时，我们需要把输出向量的每一个元素对于多个输入的梯度\u003cstrong\u003e罗列在一起\u003c/strong\u003e，罗列形成的矩阵就是\u003cstrong\u003e雅克比矩阵（Jacobian Matrix）\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e举例说明：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e若函数$f$接受三个输入$x1、x2、x3$，产生一个输出$y$，则其梯度为：\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e$$\n\\begin{equation}\nGrad = [\\frac{\\partial y}{\\partial x_1}, \\frac{\\partial y}{\\partial x_2}, \\frac{\\partial y}{\\partial x_3}]\n\\end{equation}\n$$\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e若函数$f2$接受三个输入$x1、x2、x3$，产生三个输出$y1、y2、y3$，则其雅克比矩阵为：\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e$$\n\\begin{equation}\nJacobian  = \\begin{bmatrix}\n\\frac{\\partial y_1}{\\partial x_1} \u0026amp;  \\frac{\\partial y_1}{\\partial x_2}\u0026amp;\\frac{\\partial y_1}{\\partial x_3} \\\n\\frac{\\partial y_2}{\\partial x_1} \u0026amp;  \\frac{\\partial y_2}{\\partial x_2}\u0026amp;\\frac{\\partial y_2}{\\partial x_3} \\\n\\frac{\\partial y_3}{\\partial x_1} \u0026amp;  \\frac{\\partial y_3}{\\partial x_2}\u0026amp;\\frac{\\partial y_3}{\\partial x_3}\n\\end{bmatrix}\n\\end{equation}\n$$\u003c/p\u003e\n\u003cp\u003e利用二阶导数，我们可以知道关于函数在特定方向 $d$ 上的凹凸信息，利用凹凸信息可以在一定程度上预判梯度下降法的表现效果。如果在特定方向 $d$ 上：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e二阶导数为正，则函数在方向$d$上一阶导数增加，函数值下降更慢；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e二阶导数为负，则函数在方向$d$上一阶导数减少，函数值下降更快；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e二阶导数为零，则函数在方向$d$上一阶导数不变，函数值匀速下降；\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e:star:注意在梯度下降法中是对损失函数进行下降，因此需要使用减函数来分析函数中\u003cstrong\u003e某一小段\u003c/strong\u003e（经常使用二次函数的减半部近似：二阶泰勒展开、牛顿法）中的导数变化情况；\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"海森矩阵\"\u003e海森矩阵\u003c/h2\u003e\n\u003cp\u003e和雅克比矩阵类似，\u003cstrong\u003e海森矩阵（Hessian 矩阵）\u003cstrong\u003e可以包含函数中二阶导的信息：\n$$\nHessian   = \\begin{bmatrix}\n\\frac{\\partial^2y}{\\partial x_1\\partial x_1} \u0026amp;  \\frac{\\partial^2y}{\\partial x_1\\partial x_2}\u0026amp;\\frac{\\partial^2y}{\\partial x_1\\partial x_3} \\\n\\frac{\\partial^2y}{\\partial x_2\\partial x_1} \u0026amp;  \\frac{\\partial^2y}{\\partial x_2\\partial x_2}\u0026amp;\\frac{\\partial^2y}{\\partial x_2\\partial x_3} \\\n\\frac{\\partial^2y}{\\partial x_3\\partial x_1} \u0026amp;  \\frac{\\partial^2y}{\\partial x_3\\partial x_2}\u0026amp;\\frac{\\partial^2y}{\\partial x_3\\partial x_3}\n\\end{bmatrix}\n$$\n同时由于二阶导数计算顺序的可交换性，即 $\\frac{\\partial^2y}{\\partial x_1\\partial x_2}=\\frac{\\partial^2y}{\\partial x_2\\partial x_1}$，因此\u003c/strong\u003e海森矩阵是一个对称矩阵\u003c/strong\u003e，对于对称矩阵我们可以使用\u003cstrong\u003e特征分解\u003c/strong\u003e来研究特征值和二阶导数的关系，便于我们快速获得某个方向的二阶导数。\u003c/p\u003e\n\u003cp\u003e针对于特定方向d，已知此方向的二阶导数可以写成 $d^THd$ ，则：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e:link: \u003ca href=\"https://blog.csdn.net/weixin_42397505/article/details/112066943\"\u003e基于Hessian矩阵的二阶方向导数与性质_Hi 喀什噶尔的胡杨的博客-CSDN博客_二阶方向导数\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e若d是H对应特征值λ的特征向量：\u003c/p\u003e\n\u003cp\u003e因为d为对应λ的特征向量（以下简称特征向量），则据定义有：\n$$\nHd = \\lambda d\\\n\\Rightarrow  d^THd=d^T\\lambda d = \\lambda d^Td=\\lambda    \\ \\ \\ 对称矩阵d^T = d^-\n$$\u003c/p\u003e\n\u003cp\u003e因此特征向量对应的特征值λ即为此方向的二阶导数；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e若d为其他方向：设$e_i$为$H$对应特征值$\\lambda_i$的特征向量，由上可知，\n$$\n\\lambda_i=e_i^THe_i\n$$\n可知任何一个方向$d=\\sum_i^mt_ie_i$为特征向量的线性组合，其中m为特征值个数，$t_i$为第$i$个特征向量的加权数，则：\n$$\nd^THd=(\\sum_i^mt_ie_i)^TH(\\sum_i^mt_ie_i)=\\sum_i^mt_ie_i^THt_ie_i=\\sum_i^mt_i^2\\lambda_i\n$$\n因此任意非特征向量方向的二阶导数是所有特征值的加权和，特别的，此时的加权和是一个椭球体，在二维的特征值情况下，二阶导数是一个椭圆，椭圆方程为：\n$$\ny=\\frac{\\lambda_1}{\\frac{1}{t_1^2}}+\\frac{\\lambda_2}{\\frac{1}{t_2^2}}\n$$\n\u003cimg src=\"https://img-blog.csdnimg.cn/img_convert/bb30779d25d486346799cb0fce7d34ad.png#pic_center\" alt=\"在这里插入图片描述\"\u003e\u003c/p\u003e\n\u003cp\u003e由图可知，最大二阶导数由最大特征值决定（长半轴），而最小二阶导数由最小特征值决定（短半轴）。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"海森矩阵应用\"\u003e海森矩阵应用\u003c/h2\u003e\n\u003cp\u003e在弄清海森矩阵的基本定义后，就可以使用海森矩阵的一些性质来分析优化方法中的一些问题了。如确定局部最大点、局部最小点和鞍点、确定学习率、以及使用病态条件来确定梯度下降的表现等，同时我们还可以利用Hessian矩阵来实现\u003cstrong\u003e牛顿法\u003c/strong\u003e这种优化算法，。\u003c/p\u003e\n\u003cp\u003e（本节完）\u003c/p\u003e\n","description":"本文讨论研究梯度下降法的一个有力的数学工具：海森矩阵。","image":"/blogimages/hessen.png","permalink":"https://tommycheese.github.io/blogs/h/","title":"梯度之上：Hessian 矩阵"},{"content":"","description":"🌏","image":null,"permalink":"https://tommycheese.github.io/gallery/","title":"探索|Explore"}]