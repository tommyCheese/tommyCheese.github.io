<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tommy Cheese</title>
    <link>https://tommycheese.github.io/</link>
    <description>Recent content on Tommy Cheese</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Jul 2024 23:10:20 +0800</lastBuildDate>
    <atom:link href="https://tommycheese.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>再读整洁架构之道（一）</title>
      <link>https://tommycheese.github.io/blogs/%E5%86%8D%E8%AF%BB%E6%95%B4%E6%B4%81%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%81%93%E4%B8%80/</link>
      <pubDate>Wed, 03 Jul 2024 23:10:20 +0800</pubDate>
      <guid>https://tommycheese.github.io/blogs/%E5%86%8D%E8%AF%BB%E6%95%B4%E6%B4%81%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%81%93%E4%B8%80/</guid>
      <description>前记 为什么是再读？因为在这之前笔者已经阅读过一遍架构之道这本书，但当时缺乏项目的锻炼和试错，总觉得读的不深，终于有幸在工作期间接触到了一些项目和需求，更幸运的是项目组在开发时采用的架构正好是整洁架构，详细的说，是事件驱动开发DDD+整洁架构，关于DDD的详细内容将会在之后讨论，笔者就重新阅读了这本书📚，收获颇丰，因此这一个系列，我准备用自己的拙见描述一下整洁架构，更准确的说，应该是是读书笔记，以兹同仁。&#xA;这本书的详细地址为：架构整洁之道-罗伯特 C. 马丁-微信读书 (qq.com)&#xA;本系列会以图书的章节组织作为思路，跟随作者的脚步逐渐深入，同时，由于是再读，所以不可避免的也会穿插一些图书中其他部分的内容，所以，如果你在阅读时发现了一些难于理解或者没听说过的内容，那它大概率是在之后章节中的内容。&#xA;让我们开始吧。&#xA;设计与架构的含义 设计与架构，本质上并没有区别，底层设计细节和顶层架构信息共同定义了软件系统。&#xA;软件架构的终极目标是用最小的人力成本来满足构建和维护系统的需求，因此成本可以评估一个软件架构设计的优劣。&#xA;没有经过设计、匆匆构建的系统可能成为乱麻系统，乱麻系统在构建过程中被长期忽视代码质量和设计结构优化。认真设计软件架构可以在一定程度上避免系统成为乱麻系统，从而降低成本。&#xA;软件开发具有两个核心特点：&#xA;要想跑得快，要先跑得稳； 过度自信只会使得重构设计陷入和原项目一样的困局。 两个价值维度 软件系统包含两种价值：&#xA;行为价值：让机器按照某种指定方式运转，给系统的使用者创造或者提高利润； 架构价值：软件要够灵活，更改软件的成本要做到与需求的范畴相关，与形状无关。 怎么理解需求的范畴与形状？ 笔者自己理解范畴即需求大致的范围和所属领域，而形状指需求的细节内容。&#xA;那么哪个价值维度更重要呢？ 作者认为架构价值比行为价值更重要，因为：&#xA;如果某程序可以正常工作，但是无法修改，那么当需求变更的时候它就不再能够正常工作了，我们也无法通过修改让它能继续正常工作。因此，这个程序的价值将成为0； 如果某程序目前无法正常工作，但是我们可以很容易地修改它，那么将它改好，并且随着需求变化不停地修改它，都应该是很容易的事。因此，这个程序会持续产生价值。 业务部门与研发部门经常犯的共同错误是没有把真正紧急并且重要的功能和紧急但是不重要的功能分开，结果就是重要的系统架构问题让位给了不重要的系统行为功能。&#xA;平衡系统架构的重要性与功能的紧急程度这件事，是软件研发人员自己的职责。&#xA;笔者注：同时，即便同样是研发人员，不同的小组也会存在类似问题，正如某些前端部门认为后台只需要提供一系列接口很容易，而不知道良好设计的重要性。&#xA;为好的软件架构持续斗争 如果忽视软件架构的价值，系统将会变得越来越难以维护，终会有一天，系统将会变得再也无法修改。如果系统变成了这个样子，那么说明软件开发团队没有和需求方做足够的抗争，没有完成自己应尽的职责。</description>
    </item>
    <item>
      <title>实用干货：如何把Pytorch模型参数加载到MindSpore模型？</title>
      <link>https://tommycheese.github.io/blogs/%E5%AE%9E%E7%94%A8%E5%B9%B2%E8%B4%A7%E5%A6%82%E4%BD%95%E6%8A%8Apytorch%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E5%8A%A0%E8%BD%BD%E5%88%B0mindspore%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Fri, 01 Sep 2023 22:53:58 +0530</pubDate>
      <guid>https://tommycheese.github.io/blogs/%E5%AE%9E%E7%94%A8%E5%B9%B2%E8%B4%A7%E5%A6%82%E4%BD%95%E6%8A%8Apytorch%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E5%8A%A0%E8%BD%BD%E5%88%B0mindspore%E6%A8%A1%E5%9E%8B/</guid>
      <description>问题简述 在日常的模型开发、训练过程中我们经常会遇到这样的现象：在现有的开源项目或者论文复现中，多数模型使用Pytorch设计、开发和训练推理，当我们需要使用MindSpore框架进行模型开发时，会遇到以下两个问题：&#xA;模型使用Pytorch编码； Pytorch模型训练后保存的参数无法被MindSpore模型直接加载。 对于第一个问题，我们可以根据昇思官方提供的文档：与Pytorch典型区别和PyTorch与MindSpore API映射表来完成模型的迁移；&#xA;对于模型参数的转换，在最新的MindSpore版本中MindConverter不再支持，因此可以考虑针对模型参数，我们进行手动的转换，将Pytorch模型参数转换为MindSpore能识别的格式后，再进行加载。&#xA;解决方案 模型的编码转换不再赘述。&#xA;参数转换主要思路如下：&#xA;使用Pytorch加载Pytorch模型，并取得模型参数prams_torch； 使用MindSpore加载MindSpore模型，并取得模型参数prams_ms； 将Pytorch模型的参数名和MindSpore模型参数名一一对应（有的话）； 建立torch_2_ms键名映射表，使用键名映射表将Pytorch模型参数值加载到MindSpore参数名对应的位置上； 使用MindSpore加载参数。 案例分析 不同模型的模块不相同，参数类型也不尽相同，此处我们以一个网络举例，说明转换的基本思路，不同的模型其转换思路是类似的。&#xA;EfficientNet是谷歌于2019年发表的文章，详细网络架构可查看文章描述，此处我们以EfficientNet+FC全连接层的模型为例，探讨如何进行网络模型参数的转换。&#xA;使用Pytorch加载Pytorch模型，并取得模型参数prams_torch import torch from test.efficientnet_pytorch.model import EfficientNet as EN_pytorch import pandas as pd pytorch_model = EN_pytorch.from_name(cfg[&amp;#39;model&amp;#39;], override_params={&amp;#39;num_classes&amp;#39;: 3}) pytorch_model.cuda() pytorch_weights_dict = pytorch_model.state_dict() param_torch = pytorch_weights_dict.keys() param_torch_lst = pd.DataFrame(param_torch) param_torch_lst.to_csv(&amp;#39;param_torch.csv&amp;#39;) 步骤结束后，我们就将pytorch的模型参数存到了param_torch.csv下，观察数据：&#xA;keys 0 _conv_stem.weight 1 _bn0.weight 2 _bn0.bias 3 _bn0.running_mean 4 _bn0.running_var 5 _bn0.num_batches_tracked 6 _blocks.0._depthwise_conv.weight 7 _blocks.0._bn1.weight 8 _blocks.0._bn1.bias 9 _blocks.0._bn1.running_mean 10 _blocks.</description>
    </item>
    <item>
      <title>梯度之上：Hessian 矩阵</title>
      <link>https://tommycheese.github.io/blogs/h/</link>
      <pubDate>Fri, 01 Sep 2023 22:53:58 +0530</pubDate>
      <guid>https://tommycheese.github.io/blogs/h/</guid>
      <description>本文讨论研究梯度下降法的一个有力的数学工具：海森矩阵。在讨论海森矩阵之前，需要首先了解梯度和雅克比矩阵的基本概念。&#xA;:star:本文假设读者已经熟悉梯度下降法和简单的数值分析、线性代数知识 原文链接&#xA;梯度、雅克比矩阵 梯度下降算法需要当前函数点的导数信息，当此函数点包含多个方向时，梯度是包含所有方向的（偏）导数向量。&#xA;上述情况对应于输出为一个的情况，当函数的输出也为一个向量时，我们需要把输出向量的每一个元素对于多个输入的梯度罗列在一起，罗列形成的矩阵就是雅克比矩阵（Jacobian Matrix）。&#xA;举例说明：&#xA;若函数$f$接受三个输入$x1、x2、x3$，产生一个输出$y$，则其梯度为： $$ \begin{equation} Grad = [\frac{\partial y}{\partial x_1}, \frac{\partial y}{\partial x_2}, \frac{\partial y}{\partial x_3}] \end{equation} $$&#xA;若函数$f2$接受三个输入$x1、x2、x3$，产生三个输出$y1、y2、y3$，则其雅克比矩阵为： $$ \begin{equation} Jacobian = \begin{bmatrix} \frac{\partial y_1}{\partial x_1} &amp;amp; \frac{\partial y_1}{\partial x_2}&amp;amp;\frac{\partial y_1}{\partial x_3} \ \frac{\partial y_2}{\partial x_1} &amp;amp; \frac{\partial y_2}{\partial x_2}&amp;amp;\frac{\partial y_2}{\partial x_3} \ \frac{\partial y_3}{\partial x_1} &amp;amp; \frac{\partial y_3}{\partial x_2}&amp;amp;\frac{\partial y_3}{\partial x_3} \end{bmatrix} \end{equation} $$&#xA;利用二阶导数，我们可以知道关于函数在特定方向 $d$ 上的凹凸信息，利用凹凸信息可以在一定程度上预判梯度下降法的表现效果。如果在特定方向 $d$ 上：&#xA;二阶导数为正，则函数在方向$d$上一阶导数增加，函数值下降更慢；&#xA;二阶导数为负，则函数在方向$d$上一阶导数减少，函数值下降更快；&#xA;二阶导数为零，则函数在方向$d$上一阶导数不变，函数值匀速下降；</description>
    </item>
    <item>
      <title>探索|Explore</title>
      <link>https://tommycheese.github.io/gallery/</link>
      <pubDate>Sat, 25 Jun 2022 18:35:46 +0530</pubDate>
      <guid>https://tommycheese.github.io/gallery/</guid>
      <description></description>
    </item>
  </channel>
</rss>
